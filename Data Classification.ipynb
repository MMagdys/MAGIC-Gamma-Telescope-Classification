{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Classification\n",
    "The MAGIC gamma telescope dataset:\n",
    "https://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope, it generated to simulate\n",
    "registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma\n",
    "telescope using the imaging technique allowing to discriminate statistically the information\n",
    "caused by primary gammas (signal) from the images of hadronic showers\n",
    "initiated by cosmic rays in the upper atmosphere (background).\n",
    "It is required to investigate the data deeper, split into train and test data with class labels\n",
    "g = gamma (signal) and h = hadron (background). You are asked to apply preprocessing and feature\n",
    "selection techniques and construct classification models using different approaches such as Decision\n",
    "Trees, AdaBoost, K-Nearest Neighbor (K-NN) and Logistic Regression and compare the results\n",
    "between them and between with and without applying preprocessing and feature selection. Moreover,\n",
    "you should evaluate and test the classification models accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. fLength: continuous # major axis of ellipse [mm] \n",
    "2. fWidth: continuous # minor axis of ellipse [mm] \n",
    "3. fSize: continuous # 10-log of sum of content of all pixels [in #phot] \n",
    "4. fConc: continuous # ratio of sum of two highest pixels over fSize [ratio] \n",
    "5. fConc1: continuous # ratio of highest pixel over fSize [ratio] \n",
    "6. fAsym: continuous # distance from highest pixel to center, projected onto major axis [mm] \n",
    "7. fM3Long: continuous # 3rd root of third moment along major axis [mm] \n",
    "8. fM3Trans: continuous # 3rd root of third moment along minor axis [mm] \n",
    "9. fAlpha: continuous # angle of major axis with vector to origin [deg] \n",
    "10. fDist: continuous # distance from origin to center of ellipse [mm] \n",
    "11. class: g,h # gamma (signal), hadron (background) \n",
    "\n",
    "g = gamma (signal): 12332 \n",
    "h = hadron (background): 6688 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    fAlpha     fDist class  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym',  'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
    "feature_names = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym',  'fM3Long', 'fM3Trans', 'fAlpha', 'fDist']\n",
    "data = pd.read_csv(\"magic04.data\", names=col_names)\n",
    "X = data[feature_names]\n",
    "Y = data['class']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [GaussianNB(), KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier(), AdaBoostClassifier()] \n",
    "models = {\"Naive Bayes\":GaussianNB(), \"KNN\": KNeighborsClassifier(), \"Logistic Regression\": LogisticRegression(), \"Random Forest\": RandomForestClassifier(), \"Ada Boost\": AdaBoostClassifier(), \"Decision Tree\": DecisionTreeClassifier()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Preprocessing or feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-307-85c3bb74feb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7)\n",
    "X_train.head()\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Number of mislabeled points 3651 out of 13314 total points.\n",
      "precision:  0.7175130246273267 \t Recall:  0.6455998579730086 \t FScore:  0.6516107192438991\n",
      "Model accuracy = 0.7237995092884683\n",
      "=======================================\n",
      "KNN\n",
      "Number of mislabeled points 1632 out of 13314 total points.\n",
      "precision:  0.8876186135509975 \t Recall:  0.8416156075537435 \t FScore:  0.8578529980662701\n",
      "Model accuracy = 0.8427970557308097\n",
      "=======================================\n",
      "Logistic Regression\n",
      "Number of mislabeled points 2827 out of 13314 total points.\n",
      "precision:  0.7775196761240242 \t Recall:  0.7409135071869462 \t FScore:  0.7523310959987268\n",
      "Model accuracy = 0.7960042060988434\n",
      "=======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/muhammad/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Number of mislabeled points 133 out of 13314 total points.\n",
      "precision:  0.9920403161456239 \t Recall:  0.9861104121160437 \t FScore:  0.9889701476570014\n",
      "Model accuracy = 0.8752190676480898\n",
      "=======================================\n",
      "Ada Boost\n",
      "Number of mislabeled points 2055 out of 13314 total points.\n",
      "precision:  0.8378148972585799 \t Recall:  0.8171421060494621 \t FScore:  0.8255744557127235\n",
      "Model accuracy = 0.8447248510339993\n",
      "=======================================\n",
      "Decision Tree\n",
      "Number of mislabeled points 0 out of 13314 total points.\n",
      "precision:  1.0 \t Recall:  1.0 \t FScore:  1.0\n",
      "Model accuracy = 0.8198387662110059\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "# model = GaussianNB()\n",
    "for name in models:\n",
    "    model = models[name]\n",
    "    y_pred = model.fit(X_train, Y_train).predict(X_train)\n",
    "    \n",
    "    print(name)\n",
    "    print(\"Number of mislabeled points %d out of %d total points.\"% ((Y_train != y_pred).sum(), X_train.shape[0]))\n",
    "    r = precision_recall_fscore_support(Y_train, y_pred)\n",
    "    print(\"precision: \",str( (r[0][0]+r[0][1])/2 ), \"\\t Recall: \", str( (r[1][0]+r[1][1])/2 ), \"\\t FScore: \", str( (r[2][0]+r[2][1])/2 ))\n",
    "    print(\"Model accuracy =\" , model.score(X_test,Y_test))   \n",
    "    print(\"=======================================\")\n",
    "    \n",
    "    # plt.plot(fpr, tpr, label='%s (area = %0.2f)' % (name, roc_auc))\n",
    "    # print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Preprocessing and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_k(X):\n",
    "    err = X.shape[0]\n",
    "    best_val = 2\n",
    "    \n",
    "    for i in range(1, X.shape[1]):\n",
    "    \n",
    "        X_new = SelectKBest(f_classif, k=i).fit_transform(X, Y)\n",
    "        model = GaussianNB()\n",
    "        y_pred = model.fit(X_new, Y).predict(X_new)\n",
    "        num = (Y != y_pred).sum()\n",
    "        if num < err :\n",
    "            err = num\n",
    "            best_val = i\n",
    "    \n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Number of mislabeled points 3112 out of 13314 total points.\n",
      "precision:  0.7535845893935009 \t Recall:  0.7099788800773768 \t FScore:  0.7214920549768542\n",
      "Model accuracy = 0.7630564318261479\n",
      "=======================================\n",
      "KNN\n",
      "Number of mislabeled points 2048 out of 13314 total points.\n",
      "precision:  0.841077740602201 \t Recall:  0.8130283087696497 \t FScore:  0.8238504298937415\n",
      "Model accuracy = 0.7940764107956537\n",
      "=======================================\n",
      "Logistic Regression\n",
      "Number of mislabeled points 2794 out of 13314 total points.\n",
      "precision:  0.782653596475839 \t Recall:  0.7390010511242914 \t FScore:  0.751855170195262\n",
      "Model accuracy = 0.7886435331230284\n",
      "=======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Number of mislabeled points 286 out of 13314 total points.\n",
      "precision:  0.9824003737037343 \t Recall:  0.9705107785975504 \t FScore:  0.9760508723767813\n",
      "Model accuracy = 0.7977567472835612\n",
      "=======================================\n",
      "Ada Boost\n",
      "Number of mislabeled points 2495 out of 13314 total points.\n",
      "precision:  0.8076327696203504 \t Recall:  0.7677322540252831 \t FScore:  0.780805239649033\n",
      "Model accuracy = 0.8012618296529969\n",
      "=======================================\n",
      "Decision Tree\n",
      "Number of mislabeled points 0 out of 13314 total points.\n",
      "precision:  1.0 \t Recall:  1.0 \t FScore:  1.0\n",
      "Model accuracy = 0.749211356466877\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "# print(X.shape)\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "K = best_k(X)\n",
    "# print(K)\n",
    "\n",
    "X_new = SelectKBest(f_classif, k=K).fit_transform(X, Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, train_size=0.7)\n",
    "\n",
    "for name in models:\n",
    "    model = models[name]\n",
    "    y_pred = model.fit(X_train, Y_train).predict(X_train)\n",
    "    \n",
    "    print(name)\n",
    "    print(\"Number of mislabeled points %d out of %d total points.\"% ((Y_train != y_pred).sum(), X_train.shape[0]))\n",
    "    r = precision_recall_fscore_support(Y_train, y_pred)\n",
    "    print(\"precision: \",str( (r[0][0]+r[0][1])/2 ), \"\\t Recall: \", str( (r[1][0]+r[1][1])/2 ), \"\\t FScore: \", str( (r[2][0]+r[2][1])/2 ))\n",
    "    print(\"Model accuracy =\" , model.score(X_test,Y_test))   \n",
    "    print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    neigh_score =[]\n",
    "    for i in range(1,30,1):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(X_train,y_train)\n",
    "        pred = knn.predict(X_test)\n",
    "        score = accuracy_score(y_test,pred)\n",
    "        neigh_score.append((i, score))\n",
    "    k = max(neigh_score,key=lambda x:x[1])[0]\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
